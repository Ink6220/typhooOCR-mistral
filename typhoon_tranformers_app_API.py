# typhoon_tranformers_app_API.py (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: AI-Guided Cropping)

import base64
import json
import os
from typing import Tuple, Any
from io import BytesIO

from dotenv import load_dotenv
from openai import OpenAI
from PIL import Image
import fitz  # PyMuPDF

load_dotenv()
TYPHOON_API_KEY = os.getenv("TYPHOON_API_KEY")
TYPHOON_BASE_URL = os.getenv("TYPHOON_BASE_URL", "api.opentyphoon.ai/v1")
if not TYPHOON_BASE_URL.startswith(("http://", "https://")):
    TYPHOON_BASE_URL = "https://" + TYPHOON_BASE_URL

# --- Prompt ‡πÉ‡∏´‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏´‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô JSON ---
PROMPT_AI_GUIDED_CROPPING = (
    "You are an expert document analysis system. Your task is to do two things:\n"
    "1. Reconstruct the document in the image into clean Markdown format. All tables must be plain text Markdown.\n"
    "2. Identify all figures or images in the document. For each figure, determine its bounding box [x1, y1, x2, y2] relative to the image dimensions.\n"
    "Your final output MUST be a single JSON object with two keys:\n"
    "- 'markdown_text': A string containing the full reconstructed markdown content. The figure captions should be included in this text.\n"
    "- 'figures': A list of objects, where each object has a 'caption' string (the full text of the figure's caption) and a 'bbox' list of 4 numbers [x1, y1, x2, y2].\n"
    "If no figures are found, return an empty list for the 'figures' key."
)

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ---
def process_pdf_via_api(pdf_path: str, page_num: int, task_type: str = "structure") -> Tuple[Any, str]:
    print(f"\n{'='*20} Processing Page {page_num} of PDF: {os.path.basename(pdf_path)} {'='*20}")
    
    try:
        # Step 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI ‡πÅ‡∏•‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Crop
        with fitz.open(pdf_path) as doc:
            page = doc.load_page(page_num - 1)
            pix = page.get_pixmap(dpi=300) # ‡πÉ‡∏ä‡πâ DPI ‡∏™‡∏π‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÄ‡∏´‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
            page_image_bytes = pix.tobytes("png")
            page_image_base64 = base64.b64encode(page_image_bytes).decode("utf-8")
            original_pil_image = Image.open(BytesIO(page_image_bytes))

        # Step 2: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏î‡πâ‡∏ß‡∏¢ Prompt ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        print("üöÄ Sending full page to API for combined analysis (Text + Figure BBoxes)...")
        messages = [{"role": "user", "content": [{"type": "text", "text": PROMPT_AI_GUIDED_CROPPING}, {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{page_image_base64}"}}]}]
        
        openai = OpenAI(base_url=TYPHOON_BASE_URL, api_key=TYPHOON_API_KEY)
        response = openai.chat.completions.create(model="typhoon-ocr-preview", messages=messages, max_tokens=4096,
            response_format={"type": "json_object"}) # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ AI ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON
        
        text_output = response.choices[0].message.content
        
        # Step 3: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå JSON
        final_markdown = ""
        if text_output and text_output.strip():
            print("‚úÖ Received structured JSON response from API.")
            try:
                response_data = json.loads(text_output)
                final_markdown = response_data.get('markdown_text', '')
                figures_to_embed = response_data.get('figures', [])
                
                print(f"üîé AI identified {len(figures_to_embed)} figures to embed.")

                # Step 4: ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Crop ‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏°‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà AI ‡πÉ‡∏´‡πâ‡∏°‡∏≤
                for figure in figures_to_embed:
                    caption = figure.get('caption', 'Extracted Figure')
                    bbox = figure.get('bbox')

                    if not isinstance(bbox, list) or len(bbox) != 4:
                        print(f"‚ö†Ô∏è Skipping figure with invalid BBox: {bbox}")
                        continue
                    
                    # Crop ‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å PIL Image ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
                    cropped_image = original_pil_image.crop(tuple(bbox))
                    
                    # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏õ‡πá‡∏ô Base64
                    buffered = BytesIO()
                    cropped_image.save(buffered, format="PNG")
                    base64_data = base64.b64encode(buffered.getvalue()).decode('utf-8')
                    image_data_url = f"data:image/png;base64,{base64_data}"
                    
                    final_tag = f"![{caption}]({image_data_url})"
                    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° caption ‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô Markdown ‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ó‡πá‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
                    if caption in final_markdown:
                        final_markdown = final_markdown.replace(caption, final_tag, 1)
                        print(f"‚úÖ Embedded figure for caption: '{caption[:30]}...'")
                    else:
                        print(f"‚ö†Ô∏è Caption '{caption[:30]}...' not found in markdown_text. Appending image to the end.")
                        final_markdown += "\n\n" + final_tag

            except json.JSONDecodeError:
                print("‚ö†Ô∏è API did not return a valid JSON. Using raw output.")
                final_markdown = text_output
            except Exception as e:
                print(f"‚ùå Error during embedding process: {e}")
                final_markdown = response_data.get('markdown_text', text_output)
        else:
            print("‚ö†Ô∏è API response is empty.")
            
        return None, final_markdown

    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"An error occurred: {e}"